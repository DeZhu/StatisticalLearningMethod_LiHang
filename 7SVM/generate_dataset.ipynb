{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing generate_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile generate_dataset.py\n",
    "\n",
    "# encoding=utf8\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10 #生成训练数据的个数\n",
    "\n",
    "# AX=0 相当于matlab中 null(a','r')\n",
    "def null(a, rtol=1e-5):\n",
    "    u, s, v = np.linalg.svd(a)\n",
    "    rank = (s > rtol*s[0]).sum()\n",
    "    return rank, v[rank:].T.copy()\n",
    "\n",
    "# 符号函数，之后要进行向量化\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    elif x < 0:\n",
    "        return -1\n",
    "#noisy=False，那么就会生成N的dim维的线性可分数据X，标签为y\n",
    "#noisy=True, 那么生成的数据是线性不可分的,标签为y\n",
    "def mk_data(N, noisy=False):\n",
    "    rang = [-10,10]\n",
    "    dim = 2\n",
    "\n",
    "    X=np.random.rand(dim,N)*(rang[1]-rang[0])+rang[0]\n",
    "\n",
    "    while True:\n",
    "        Xsample = np.concatenate((np.ones((1,dim)), np.random.rand(dim,dim)*(rang[1]-rang[0])+rang[0]))\n",
    "        k,w=null(Xsample.T)\n",
    "        y = sign(np.dot(w.T,np.concatenate((np.ones((1,N)), X))))\n",
    "        if np.all(y):\n",
    "            break\n",
    "\n",
    "    if noisy == True:\n",
    "        idx = random.sample(range(1,N), N/10)\n",
    "\n",
    "        for id in idx:\n",
    "            y[0][id] = -y[0][id]\n",
    "\n",
    "    return (X,y,w)\n",
    "\n",
    "def data_visualization(X,y,title):\n",
    "    class_1 = [[],[]]\n",
    "    class_2 = [[],[]]\n",
    "\n",
    "    size = len(y)\n",
    "\n",
    "    for i in range(size):\n",
    "        X_1 = X[0][i]\n",
    "        X_2 = X[1][i]\n",
    "\n",
    "        if y[i] == 1:\n",
    "            class_1[0].append(X_1)\n",
    "            class_1[1].append(X_2)\n",
    "        else:\n",
    "            class_2[0].append(X_1)\n",
    "            class_2[1].append(X_2)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "    plt.title(title)\n",
    "\n",
    "    axes = plt.subplot(111)\n",
    "\n",
    "    type1 = axes.scatter(class_1[0], class_1[1], s=20, c='red')\n",
    "    type2 = axes.scatter(class_2[0], class_2[1], s=20, c='green')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def rebuild_features(features):\n",
    "    size = len(features[0])\n",
    "\n",
    "    new_features = []\n",
    "    for i in range(size):\n",
    "        new_features.append([features[0][i],features[1][i]])\n",
    "\n",
    "    return new_features\n",
    "\n",
    "def generate_dataset(size, noisy = False, visualization = True):\n",
    "    global sign\n",
    "    sign = np.vectorize(sign)\n",
    "    X,y,w = mk_data(size,False)\n",
    "    y = list(y[0])\n",
    "\n",
    "    if visualization:\n",
    "        data_visualization(X,y,'all data')         #数据可视化\n",
    "\n",
    "    testset_size = int(len(y)*0.333)\n",
    "\n",
    "    indexes = [i for i in range(len(y))]\n",
    "    test_indexes = random.sample(indexes,testset_size)\n",
    "    train_indexes = list(set(indexes)-set(test_indexes))\n",
    "\n",
    "    trainset_features = [[],[]]\n",
    "    trainset_labels = []\n",
    "\n",
    "    testset_features = [[],[]]\n",
    "    testset_labels = []\n",
    "\n",
    "    for i in test_indexes:\n",
    "        testset_features[0].append(X[0][i])\n",
    "        testset_features[1].append(X[1][i])\n",
    "        testset_labels.append(y[i])\n",
    "\n",
    "\n",
    "    if visualization:\n",
    "        data_visualization(testset_features,testset_labels,'test set')\n",
    "\n",
    "    for i in train_indexes:\n",
    "        trainset_features[0].append(X[0][i])\n",
    "        trainset_features[1].append(X[1][i])\n",
    "        trainset_labels.append(y[i])\n",
    "\n",
    "    if visualization:\n",
    "        data_visualization(trainset_features,trainset_labels,'train set')\n",
    "\n",
    "    return rebuild_features(trainset_features),trainset_labels,rebuild_features(testset_features),testset_labels\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    size = 1000\n",
    "    generate_dataset(size)\n",
    "\n",
    "    # generate_dataset\n",
    "    # print(sign)\n",
    "    # sign = np.vectorize(sign)\n",
    "    # X,y,w = mk_data(size,False)\n",
    "    #\n",
    "    # data_visualization(X,y)\n",
    "# encoding=utf8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
